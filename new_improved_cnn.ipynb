{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('.\\dataset'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e02f846c1a63f12c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Directory with our training healthy pictures\n",
    "a_dir = os.path.join('./dataset/consumable')\n",
    "\n",
    "# Directory with our training not healthy pictures\n",
    "b_dir = os.path.join('./dataset/not_consumable')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "700aa5f7824726d3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "a_names = os.listdir(a_dir)\n",
    "print(a_names[:10])\n",
    "b_names = os.listdir(b_dir)\n",
    "print(b_names[:10])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f10ab2075ab487f3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print('total healthy images:', len(os.listdir(a_dir)))\n",
    "print('total non-healthy images:', len(os.listdir(b_dir)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56ed969c107b98ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 10\n",
    "ncols = 2\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e1f6e69e5ec63c8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "a_pix = [os.path.join(a_dir, fname)\n",
    "                for fname in a_names[pic_index-8:pic_index]]\n",
    "b_pix = [os.path.join(b_dir, fname)\n",
    "                for fname in b_names[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(a_pix + b_pix):\n",
    "  sp = plt.subplot(nrows, ncols, (i % (nrows * ncols)) + 1)\n",
    "  sp.axis('Off')\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40fc24a09d9af28"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_dir = './dataset'\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "input_shape = (300, 300, 3)\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for category in os.listdir(data_dir):\n",
    "    category_dir = os.path.join(data_dir, category)\n",
    "    if os.path.isdir(category_dir):\n",
    "        for image_filename in os.listdir(category_dir):\n",
    "            if image_filename.endswith('.jpg'):\n",
    "                image_path = os.path.join(category_dir, image_filename)\n",
    "                image_paths.append(image_path)\n",
    "                labels.append(category)\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f83cdcfdc3ce1508"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(train_image_paths),len(test_image_paths), len(train_labels), len(test_labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67855c8f8609b5ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "434d31ec9dbb2f74"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import dump\n",
    "\n",
    "# Create a label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder with your labels\n",
    "# Assuming `labels` is your list of labels\n",
    "label_encoder.fit(labels)\n",
    "\n",
    "# Save the encoder\n",
    "dump(label_encoder, 'label_encoder.joblib')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ca7a0c79f0683a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e485e6fc03cb1ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f10f95d3949a2c0e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({'image_path': train_image_paths, 'label': train_labels}),\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(150,150),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    pd.DataFrame({'image_path': test_image_paths, 'label': test_labels}),\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(150,150),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "527dcd9643dafcf9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=30, steps_per_epoch=8, validation_data = validation_generator, verbose = 1, validation_steps=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f421c2e6c17acdc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation Loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a9967dc66f30cc2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.save('new_mango.h5')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "717711ac317071"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
